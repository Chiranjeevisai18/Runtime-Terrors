E:\GruhaBuddy\backend\venv\Lib\site-packages\langchain_core\_api\deprecation.py:27: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.
  from pydantic.v1.fields import FieldInfo as FieldInfoV1

--- Testing Product Scraper (Amazon) ---
Scraping Amazon for 'modern beige sofa'...
Scraper found 0 results.
Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash
Please retry in 27.562235802s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 20
}
, retry_delay {
  seconds: 27
}
].
FAILURE: Scraper returned no results.

--- Testing Booking Agent (Gemini + Playwright Tools) ---
Initiating booking for: https://www.amazon.com/dp/B08P2H8S1C
AGENT_LOOP: Turn 1
Traceback (most recent call last):
  File "E:\GruhaBuddy\backend\test_booking_system.py", line 57, in <module>
    test_booking_agent()
    ~~~~~~~~~~~~~~~~~~^^
  File "E:\GruhaBuddy\backend\test_booking_system.py", line 37, in test_booking_agent
    result = run_booking_agent(test_url, user_id=1)
  File "E:\GruhaBuddy\backend\services\agent_service.py", line 59, in run_booking_agent
    response = llm_with_tools.invoke(messages)
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\langchain_core\runnables\base.py", line 5720, in invoke
    return self.bound.invoke(
           ~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
        self._merge_configs(config),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        **{**self.kwargs, **kwargs},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 395, in invoke
    self.generate_prompt(
    ~~~~~~~~~~~~~~~~~~~~^
        [self._convert_input(input)],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<6 lines>...
        **kwargs,
        ^^^^^^^^^
    ).generations[0][0],
    ^
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 842, in generate
    self._generate_with_cache(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        m,
        ^^
    ...<2 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
        messages, stop=stop, run_manager=run_manager, **kwargs
    )
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\langchain_google_genai\chat_models.py", line 951, in _generate
    response: GenerateContentResponse = _chat_with_retry(
                                        ~~~~~~~~~~~~~~~~^
        request=request,
        ^^^^^^^^^^^^^^^^
    ...<2 lines>...
        metadata=self.default_metadata,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\langchain_google_genai\chat_models.py", line 196, in _chat_with_retry
    return _chat_with_retry(**kwargs)
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\tenacity\__init__.py", line 331, in wrapped_f
    return copy(f, *args, **kw)
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\tenacity\__init__.py", line 470, in __call__
    do = self.iter(retry_state=retry_state)
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\tenacity\__init__.py", line 371, in iter
    result = action(retry_state)
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\tenacity\__init__.py", line 413, in exc_check
    raise retry_exc.reraise()
          ~~~~~~~~~~~~~~~~~^^
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\tenacity\__init__.py", line 184, in reraise
    raise self.last_attempt.result()
          ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Python314\Lib\concurrent\futures\_base.py", line 443, in result
    return self.__get_result()
           ~~~~~~~~~~~~~~~~~^^
  File "C:\Python314\Lib\concurrent\futures\_base.py", line 395, in __get_result
    raise self._exception
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\tenacity\__init__.py", line 473, in __call__
    result = fn(*args, **kwargs)
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\langchain_google_genai\chat_models.py", line 194, in _chat_with_retry
    raise e
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\langchain_google_genai\chat_models.py", line 178, in _chat_with_retry
    return generation_method(**kwargs)
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 830, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
        exc,
    ...<6 lines>...
        timeout,
    )
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "E:\GruhaBuddy\backend\venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash
Please retry in 24.905429618s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 20
}
, retry_delay {
  seconds: 24
}
]
